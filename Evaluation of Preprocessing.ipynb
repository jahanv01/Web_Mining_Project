{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation of Preprocessing Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"downsampled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29999, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>44769940</td>\n",
       "      <td>R315SMIS3GYVLG</td>\n",
       "      <td>B0010K6TXQ</td>\n",
       "      <td>552991445</td>\n",
       "      <td>Pyle PTA1000 1000W Professional Power Amplifier</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Broken on arrival</td>\n",
       "      <td>Only one channel worked.</td>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>29650062</td>\n",
       "      <td>R15FX2RLC369WA</td>\n",
       "      <td>B00V3KM1Y4</td>\n",
       "      <td>626268159</td>\n",
       "      <td>iGotTech Cable Clips &amp; Cord Management System:...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Holding up so far</td>\n",
       "      <td>I've been using these by my bed for a little l...</td>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>51949299</td>\n",
       "      <td>R2SXWFPDZZBLIM</td>\n",
       "      <td>B00W9TDOMG</td>\n",
       "      <td>750325480</td>\n",
       "      <td>Lonve Music Player 16GB MP4/MP3 Player Black 1...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>At this price? 5 stars, easily.</td>\n",
       "      <td>OK, I've reviewed a similar player and hated i...</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>44531528</td>\n",
       "      <td>R2PNB95FOWAFVU</td>\n",
       "      <td>B00R3M4KEU</td>\n",
       "      <td>605481722</td>\n",
       "      <td>Jarv NMotion PRO Sport Wireless Bluetooth Earb...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Good quality headphones.</td>\n",
       "      <td>I've enjoyed these headphones for a few weeks ...</td>\n",
       "      <td>2015-08-16</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>43639082</td>\n",
       "      <td>R3NJ9O0BNG216G</td>\n",
       "      <td>B00HY4PICU</td>\n",
       "      <td>493178902</td>\n",
       "      <td>FRiEQ 3.5mm Male To Male Car and Home Stereo C...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Awesome cable. Thanks to LOWERPRICEUSA for the...</td>\n",
       "      <td>2015-08-21</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     44769940  R315SMIS3GYVLG  B0010K6TXQ       552991445   \n",
       "1          US     29650062  R15FX2RLC369WA  B00V3KM1Y4       626268159   \n",
       "2          US     51949299  R2SXWFPDZZBLIM  B00W9TDOMG       750325480   \n",
       "3          US     44531528  R2PNB95FOWAFVU  B00R3M4KEU       605481722   \n",
       "4          US     43639082  R3NJ9O0BNG216G  B00HY4PICU       493178902   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0    Pyle PTA1000 1000W Professional Power Amplifier      Electronics   \n",
       "1  iGotTech Cable Clips & Cord Management System:...      Electronics   \n",
       "2  Lonve Music Player 16GB MP4/MP3 Player Black 1...      Electronics   \n",
       "3  Jarv NMotion PRO Sport Wireless Bluetooth Earb...      Electronics   \n",
       "4  FRiEQ 3.5mm Male To Male Car and Home Stereo C...      Electronics   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            1              0            0    N                 Y   \n",
       "1            4              0            0    N                 Y   \n",
       "2            5              3            3    N                 N   \n",
       "3            4              0            0    N                 N   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "                   review_headline  \\\n",
       "0                Broken on arrival   \n",
       "1                Holding up so far   \n",
       "2  At this price? 5 stars, easily.   \n",
       "3         Good quality headphones.   \n",
       "4                       Five Stars   \n",
       "\n",
       "                                         review_body review_date sentiment  \n",
       "0                           Only one channel worked.  2015-08-28  Negative  \n",
       "1  I've been using these by my bed for a little l...  2015-08-22  Positive  \n",
       "2  OK, I've reviewed a similar player and hated i...  2015-08-25  Positive  \n",
       "3  I've enjoyed these headphones for a few weeks ...  2015-08-16  Positive  \n",
       "4  Awesome cable. Thanks to LOWERPRICEUSA for the...  2015-08-21  Positive  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually we only need the content(i.e. review) & the sentiment for classification\n",
    "df = df[[\"review_body\", \"sentiment\"]]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive Bayes Model without preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (23999,)/ x_train: (23999,)\n",
      "y_test: (6000,)/ x_test: (6000,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set \n",
    "x_train, x_test = train_test_split(df, test_size=0.2, random_state = 42, stratify=df['sentiment'])\n",
    "\n",
    "y_train = x_train['sentiment']\n",
    "y_test = x_test['sentiment']\n",
    "\n",
    "x_train.drop(columns = ['sentiment'], inplace= True)\n",
    "x_test.drop(columns = ['sentiment'], inplace= True)\n",
    "x_train = x_train['review_body']\n",
    "x_test = x_test['review_body']\n",
    "\n",
    "\n",
    "print (f\"y_train: {y_train.shape}/ x_train: {x_train.shape}\")\n",
    "print (f\"y_test: {y_test.shape}/ x_test: {x_test.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape\t:(23999, 20221)\n",
      "Test set shape\t:(6000, 20221)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "\n",
    "print (f'Train set shape\\t:{X_train_tfidf.shape}\\nTest set shape\\t:{X_test_tfidf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7823333333333333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.11      0.20      1008\n",
      "     Neutral       0.00      0.00      0.00       411\n",
      "    Positive       0.78      1.00      0.88      4581\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.58      0.37      0.36      6000\n",
      "weighted avg       0.76      0.78      0.70      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 115    0  893]\n",
      " [   1    0  410]\n",
      " [   2    0 4579]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing, Removing punctuation, specific characters, Tokenization & Stopword removal, Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text normalization\n",
    "def normalize_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Removing punctuation (not used)\n",
    "def remove_punctuation(text):\n",
    "    text = str(text)\n",
    "    punctuations = string.punctuation\n",
    "    return text.translate(str.maketrans('', '', punctuations))\n",
    "\n",
    "# Removing special characters (not used)\n",
    "def remove_spec_char(text):\n",
    "    text = str(text)\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Tokenization & Stopword removal\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join([word for word in tokens if word not in stop_words])\n",
    "\n",
    "# Lemmatization (not used)\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "    #return lemmatized_tokens\n",
    "\n",
    "# Stemming \n",
    "def stem_words(text):\n",
    "    ps = PorterStemmer()\n",
    "    return ' '.join([ps.stem(word) for word in text.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing steps\n",
    "\n",
    "# lowercase words, remove punctuation & special characters\n",
    "df[\"review_body\"] = df[\"review_body\"].apply(normalize_text)\n",
    "#df[\"review_body\"] = df[\"review_body\"].apply(remove_punctuation)\n",
    "#df[\"review_body\"] = df[\"review_body\"].apply(remove_spec_char)\n",
    "\n",
    "#tokenization and stopwords removal, stemming or lemmatization\n",
    "df[\"review_body\"] = df[\"review_body\"].apply(remove_stopwords)\n",
    "#df[\"review_body\"] = df[\"review_body\"].apply(lemmatize_text)\n",
    "df[\"review_body\"] = df[\"review_body\"].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one channel worked .</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'ve using bed little le month . 've holding pr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok , 've reviewed similar player hated , like ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'ve enjoyed headphone week . issue bluetooth s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awesome cable . thanks lowerpriceusa good deal...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>work fine money .</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>work great</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reasonable price , prompt service</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body sentiment\n",
       "0                               one channel worked .  Negative\n",
       "1  've using bed little le month . 've holding pr...  Positive\n",
       "2  ok , 've reviewed similar player hated , like ...  Positive\n",
       "3  've enjoyed headphone week . issue bluetooth s...  Positive\n",
       "4  awesome cable . thanks lowerpriceusa good deal...  Positive\n",
       "5                                              great  Positive\n",
       "6                                  work fine money .  Positive\n",
       "7                                         work great  Positive\n",
       "8                  reasonable price , prompt service  Positive\n",
       "9                                                     Positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive Bayes Model with preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (23999,)/ x_train: (23999,)\n",
      "y_test: (6000,)/ x_test: (6000,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set \n",
    "x_train, x_test = train_test_split(df, test_size=0.2, random_state = 42, stratify=df['sentiment'])\n",
    "\n",
    "y_train = x_train['sentiment']\n",
    "y_test = x_test['sentiment']\n",
    "\n",
    "x_train.drop(columns = ['sentiment'], inplace= True)\n",
    "x_test.drop(columns = ['sentiment'], inplace= True)\n",
    "x_train = x_train['review_body']\n",
    "x_test = x_test['review_body']\n",
    "\n",
    "print (f\"y_train: {y_train.shape}/ x_train: {x_train.shape}\")\n",
    "print (f\"y_test: {y_test.shape}/ x_test: {x_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7848333333333334\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      0.13      0.23      1008\n",
      "     Neutral       0.00      0.00      0.00       411\n",
      "    Positive       0.78      1.00      0.88      4581\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.58      0.38      0.37      6000\n",
      "weighted avg       0.76      0.78      0.71      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 132    0  876]\n",
      " [   1    0  410]\n",
      " [   4    0 4577]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
